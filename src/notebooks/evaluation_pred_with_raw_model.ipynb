{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, balanced_accuracy_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pickle\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpl.style.use('seaborn-v0_8-colorblind')\n",
    "plt.rcParams[\"font.family\"] = \"serif\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "races = ['Indian', 'Asian', 'African', 'Caucasian']\n",
    "categories = ['skin_type', 'eye_type', 'nose_type', 'lip_type', 'hair_type', 'hair_color']\n",
    "category_names = ['Skin Type', 'Eye Type', 'Nose Type', 'Lip Type', 'Hair Type', 'Hair Color']\n",
    "lambda_file_names = [\"1\"]\n",
    "lambda_values = [1]\n",
    "data_rate_values = [\"clean\"]\n",
    "qualities = [\"q_0001\", \"q_0009\", \"q_1\", \"q_2\", \"q_3\"]\n",
    "qres = [\"1\", \"3\", \"6\", \"9\", \"12\"]\n",
    "qarv = [\"lmb_1\", \"lmb_4\", \"lmb_8\", \"lmb_16\", \"lmb_32\" ]\n",
    "rates = []\n",
    "race_markers = ['s', 'o', '^', '*']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## for a model and generate accuracies for all rates\n",
    "def generate_results(dataset=\"celebA\", model=\"hyperprior\"):\n",
    "    rates = []\n",
    "    results = {}\n",
    "    for i, q in enumerate(qualities):\n",
    "        results[q] = {}\n",
    "        #Iterate through qualities and pull dictionaries\n",
    "        with open(f'/media/global_data/fair_neural_compression_data/pred_with_raw_model_debug/{model}/{dataset}/{q}/sep_predictions.pkl', 'rb') as f:\n",
    "            all_predictions = pickle.load(f)\n",
    "        with open(f'/media/global_data/fair_neural_compression_data/pred_with_raw_model_debug/hyperprior/celebA/clean/sep_labels.pkl', 'rb') as f:\n",
    "            all_labels = pickle.load(f)\n",
    "\n",
    "        if model == \"qarv\":\n",
    "            with open(f'/media/global_data/fair_neural_compression_data/decoded_rfw/decoded_64x64/qarv/{dataset}/{qarv[i]}/stats.json', 'r') as json_file:\n",
    "                        data_dict = json.load(json_file)\n",
    "            bpp = data_dict['results']['bpp']\n",
    "\n",
    "        elif model == \"qres17m\":\n",
    "            with open(f'/media/global_data/fair_neural_compression_data/decoded_rfw/decoded_64x64/qres17m_lmb_64/{dataset}/{qres[i]}/stats.json', 'r') as json_file:\n",
    "                        data_dict = json.load(json_file)\n",
    "            bpp = data_dict['results']['bpp']\n",
    "        else:\n",
    "            with open(f'/media/global_data/fair_neural_compression_data/decoded_rfw/decoded_64x64/{model}/{dataset}/{q}/stats.json', 'r') as json_file:\n",
    "                        data_dict = json.load(json_file)\n",
    "            bpp = data_dict['est_bpp']\n",
    "        rates.append(bpp)\n",
    "        merged_skin_type={\n",
    "              'African':([4, 5], 3), \n",
    "              'Asian':([3, 2], 1), \n",
    "              'Caucasian':([3, 2], 1), \n",
    "              'Indian':([4,3], 2)\n",
    "        }\n",
    "        merged_hair_type={\n",
    "                'African':([1, 3], 0), \n",
    "                'Asian':([2, 3], 0), \n",
    "                'Caucasian':([2, 3], 0), \n",
    "                'Indian':([2, 3], 0)\n",
    "        }\n",
    "        merged_hair_color={\n",
    "                'African':([2, 3], 0), \n",
    "                'Asian':([2, 3], 0), \n",
    "                'Caucasian':([1, 2], 0), \n",
    "                'Indian':([2, 3], 0)\n",
    "        }\n",
    "        for race in races:\n",
    "            results[q][race] = {}\n",
    "            for cat in categories:\n",
    "                pred = all_predictions[race][cat]\n",
    "                labels = all_labels[race][cat]\n",
    "                if cat == 'skin_type':\n",
    "                    for target in merged_skin_type[race][0]:\n",
    "                        pred[pred==target] = merged_skin_type[race][1]\n",
    "                        labels[labels==target] = merged_skin_type[race][1]\n",
    "\n",
    "                if cat == 'hair_type':  \n",
    "                    for target in merged_hair_type[race][0]:\n",
    "                        pred[pred==target] = merged_hair_type[race][1]\n",
    "                        labels[labels==target] = merged_hair_type[race][1] \n",
    "\n",
    "                if cat == 'hair_color':\n",
    "                    for target in merged_hair_color[race][0]:\n",
    "                        pred[pred==target] = merged_hair_color[race][1]\n",
    "                        labels[labels==target] = merged_hair_color[race][1]   \n",
    "                          \n",
    "                score = accuracy_score(pred, labels)\n",
    "                results[q][race][cat] = score\n",
    "                # print(q, race, cat)\n",
    "                # print(confusion_matrix(labels, pred))\n",
    "        \n",
    "    temp = {}\n",
    "    for cat in categories:\n",
    "        temp[cat] = {}\n",
    "        for race in races:\n",
    "            temp[cat][race] = [results[q][race][cat] for q in qualities]\n",
    "    return temp, rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_clean_pred(dataset=\"celebA\", model=\"hyperprior\"):\n",
    "    with open(f'/media/global_data/fair_neural_compression_data/pred_with_raw_model_debug/{model}/{dataset}/clean/sep_predictions.pkl', 'rb') as f:\n",
    "                all_predictions = pickle.load(f)\n",
    "    with open(f'/media/global_data/fair_neural_compression_data/pred_with_raw_model_debug/hyperprior/celebA/clean/sep_labels.pkl', 'rb') as f:\n",
    "                all_labels = pickle.load(f)\n",
    "    results = {}\n",
    "    merged_skin_type={\n",
    "            'African':([4, 5], 3), \n",
    "            'Asian':([3, 2], 1), \n",
    "            'Caucasian':([3, 2], 1), \n",
    "            'Indian':([4,3], 2)\n",
    "    }\n",
    "    merged_hair_type={\n",
    "            'African':([1, 3], 0), \n",
    "            'Asian':([2, 3], 0), \n",
    "            'Caucasian':([2, 3], 0), \n",
    "            'Indian':([2, 3], 0)\n",
    "    }\n",
    "    merged_hair_color={\n",
    "            'African':([2, 3], 0), \n",
    "            'Asian':([2, 3], 0), \n",
    "            'Caucasian':([1, 2], 0), \n",
    "            'Indian':([2, 3], 0)\n",
    "    }\n",
    "    for race in races:\n",
    "            results[race] = {}\n",
    "            for cat in categories:\n",
    "                pred = all_predictions[race][cat]\n",
    "                labels = all_labels[race][cat]\n",
    "                if cat == 'skin_type':\n",
    "                    for target in merged_skin_type[race][0]:\n",
    "                        pred[pred==target] = merged_skin_type[race][1]\n",
    "                        labels[labels==target] = merged_skin_type[race][1]\n",
    "\n",
    "                if cat == 'hair_type':  \n",
    "                    for target in merged_hair_type[race][0]:\n",
    "                        pred[pred==target] = merged_hair_type[race][1]\n",
    "                        labels[labels==target] = merged_hair_type[race][1] \n",
    "\n",
    "                if cat == 'hair_color':\n",
    "                    for target in merged_hair_color[race][0]:\n",
    "                        pred[pred==target] = merged_hair_color[race][1]\n",
    "                        labels[labels==target] = merged_hair_color[race][1]  \n",
    "                results[race][cat] = accuracy_score(pred, labels)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"qarv\"\n",
    "# hyperprior, mbt2018, cheng2020-attn, qres17m, qarv\n",
    "temp, rates = generate_results(model=model)\n",
    "ff_temp, ff_rates = generate_results(\"fairface\", model=model)\n",
    "results = get_clean_pred()\n",
    "ff_results = get_clean_pred()\n",
    "mpl.style.use('seaborn-v0_8-colorblind')\n",
    "print(results)\n",
    "\n",
    "def plot_races_and_fairness(temp, rates, results, trained_on, figure_name, write_image=False):\n",
    "    fig, axes = plt.subplots(1, 6, figsize=(12, 2), sharey=True, sharex=True)\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    #colors = ['b', 'y', 'g', 'r']\n",
    "    \n",
    "    for i, cat in enumerate(categories):\n",
    "        zz = []\n",
    "        axes[i].set_title(category_names[i])\n",
    "        for j, race in enumerate(races):\n",
    "            axes[i].plot(rates, temp[cat][race], marker=race_markers[j], label=race,) #color = colors[j],\n",
    "            zz.append(temp[cat][race])\n",
    "        #print(zz)\n",
    "        axes[i].plot(rates, np.array(zz).max(0) - np.array(zz).min(0), marker=\"d\", linestyle = \"dashdot\" , color = plt.rcParams['axes.prop_cycle'].by_key()['color'][5], label=\"Bias\")\n",
    "        print(np.array(zz).max(0) - np.array(zz).min(0))\n",
    "\n",
    "        axes[i].set_xlabel(\"Bits per pixel\")\n",
    "        axes[i].set_ylabel(\"Accuracy\")\n",
    "        axes[i].set_xticks(np.arange(0.1, round(max(rates), 1)+0.1, 0.1))\n",
    "\n",
    "    #for j, race in enumerate(races):\n",
    "    #    for i, cat in enumerate(categories):\n",
    "    #        axes[i%2][i//2].axhline(results[race][cat], linestyle=\"--\", color=plt.rcParams['axes.prop_cycle'].by_key()['color'][j] )#color=colors[j])\n",
    "    axes[0].legend(bbox_to_anchor=(5.5, -0.3), ncol = 5)\n",
    "    fig.subplots_adjust(hspace=0.3)\n",
    "    #plt.suptitle(model)\n",
    "    if write_image:\n",
    "        fig.savefig(os.path.join('../../plots/pred_with_raw_model', model, f'{model}_{trained_on}_{figure_name}.png'), bbox_inches='tight',dpi=200)\n",
    "        fig.savefig(os.path.join('../../plots/pred_with_raw_model', model, f'{model}_{trained_on}_{figure_name}.pdf'), bbox_inches='tight', dpi=200)\n",
    "    plt.show()\n",
    "    \n",
    "plot_races_and_fairness(temp, rates, results, 'celeba', 'racial_disparity', write_image=True)\n",
    "plot_races_and_fairness(ff_temp, ff_rates, ff_results, 'fairface', 'racial_disparity', write_image=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_races_and_fairness_single(temp, rates, results):\n",
    "    categories = [\"eye_type\"]\n",
    "    fig, axes = plt.subplots(len(categories), figsize=(2, 1.6), sharey=True)\n",
    "    \n",
    "    colors = ['b', 'y', 'g', 'r']\n",
    "    # axes.set_title(\"Accuracy vs Rate (by Group)\")\n",
    "    for i, cat in enumerate(categories):\n",
    "        zz = []\n",
    "\n",
    "        for j, race in enumerate(races):\n",
    "            axes.plot(rates, temp[cat][race], marker=race_markers[j], markersize=4, color=plt.rcParams['axes.prop_cycle'].by_key()['color'][j], label=race)\n",
    "\n",
    "            zz.append(temp[cat][race])\n",
    "        axes.plot(rates, np.array(zz).max(0) - np.array(zz).min(0), marker=\"d\", markersize=4, linestyle = \"dashdot\" , color = plt.rcParams['axes.prop_cycle'].by_key()['color'][5], label=\"Bias\")\n",
    "        #print(np.array(zz).max(0) - np.array(zz).min(0))\n",
    "\n",
    "    # for j, race in enumerate(races):\n",
    "    #     for i, cat in enumerate(categories):\n",
    "    #         axes.axhline(results[race][cat], linestyle=\"--\", color=plt.rcParams['axes.prop_cycle'].by_key()['color'][j])\n",
    "    axes.set_xticks([0.1, 0.2, 0.3, 0.4])\n",
    "    axes.legend(bbox_to_anchor=(1, 1))\n",
    "    axes.set_xlabel(\"Bits per pixel\")\n",
    "    axes.set_ylabel(\"Accuracy\")\n",
    "    fig.savefig(os.path.join('../../plots/pred_with_raw_model', model, f'{model}_celeba_eye_fairness.pdf'),bbox_inches='tight', dpi=200)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_races_and_fairness_single(temp, rates, results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_fairness(temp, rates, trained_on, write_image=False):\n",
    "    fig, axes = plt.subplots(1, figsize=(2, 1.6), sharey=True)\n",
    "\n",
    "    #colors = ['b', 'y', 'g', 'r', \"darkviolet\", \"slategrey\"]\n",
    "    markers = ['s', 'o', '^', '*', \"v\", \"P\"]\n",
    "    linestyles = ['solid', 'dotted', 'dashed', 'dashdot', (5, (10, 3)), (0, (5, 1))]\n",
    "\n",
    "    # axes.set_title(f\"Fairness, {model}, {trained_on}\")\n",
    "    \n",
    "    for i, cat in enumerate(categories):\n",
    "        zz = []\n",
    "        for j, race in enumerate(races):\n",
    "            #axes[i].plot(rates, temp[cat][race], marker=race_markers[j], color = colors[j], label=race)\n",
    "            zz.append(temp[cat][race])\n",
    "        axes.plot(rates, np.array(zz).max(0) - np.array(zz).min(0), marker=markers[i], markersize=4, linestyle=linestyles[i], label=category_names[i])\n",
    "    axes.legend(bbox_to_anchor=(1, 1.05))\n",
    "    axes.set_xlabel(\"Bits per pixel\")\n",
    "    axes.set_ylabel(\"Bias\")\n",
    "    axes.set_xticks([0.1, 0.2, 0.3, 0.4])\n",
    "\n",
    "    #for j, race in enumerate(races):\n",
    "    #    for i, cat in enumerate(categories):\n",
    "    #        axes[i].axhline(results[race][cat], linestyle=\"--\", color=colors[j])\n",
    "    figure_name= 'all_fairness'\n",
    "    if write_image:\n",
    "        fig.savefig(os.path.join('../../plots/pred_with_raw_model', model, f'{model}_{trained_on}_{figure_name}.png'), bbox_inches='tight', dpi=200)\n",
    "        fig.savefig(os.path.join('../../plots/pred_with_raw_model', model, f'{model}_{trained_on}_{figure_name}.pdf'), bbox_inches='tight', dpi=200)\n",
    "        \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_fairness(temp, rates, 'celeba', write_image=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_fairness(ff_temp, ff_rates, 'fairface', write_image=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_fairness_comparison(temp, ff_temp, rates, write_image=False):\n",
    "    categories = [\"skin_type\", \"eye_type\", \"hair_color\"]\n",
    "    fig, axes = plt.subplots(1, figsize=(2.5, 2), sharey=True)\n",
    "    markers = ['s', 'o', '^', '*', \"v\", \"D\"]\n",
    "\n",
    "    # axes.set_title(f\"FairFace/celebA Comparison, {model}\")\n",
    "    \n",
    "    for i, cat in enumerate(categories):\n",
    "        zz = []\n",
    "        yy = []\n",
    "        for j, race in enumerate(races):\n",
    "            #axes[i].plot(rates, temp[cat][race], marker=race_markers[j], color = colors[j], label=race)\n",
    "            zz.append(temp[cat][race])\n",
    "            yy.append(ff_temp[cat][race])\n",
    "        axes.plot(rates, np.array(zz).max(0) - np.array(zz).min(0), marker=markers[i],  linestyle = \"-\", label=f\"{category_names[i]} (CelebA)\", color=plt.rcParams['axes.prop_cycle'].by_key()['color'][i])\n",
    "        axes.plot(rates, np.array(yy).max(0) - np.array(yy).min(0), marker=markers[i], linestyle = \"--\", label=f\"{category_names[i]} (FairFace)\", color = plt.rcParams['axes.prop_cycle'].by_key()['color'][i])\n",
    "    axes.legend(bbox_to_anchor=(1.05, 1))\n",
    "    axes.set_xlabel(\"Bits per pixel\")\n",
    "    axes.set_ylabel(\"Bias\")\n",
    "    # axes.set_xticks([0.1, 0.2, 0.3, 0.4])\n",
    "        #print(np.array(zz).max(0) - np.array(zz).min(0))\n",
    "    \n",
    "        \n",
    "    #for i, cat in enumerate(categories):\n",
    "       # max_acc = 0\n",
    "       # min_acc = 1\n",
    "       # for j, race in enumerate(races):\n",
    "       #     value = results[race][cat]\n",
    "       #     if value > max_acc:\n",
    "                #max_acc = value\n",
    "       #     if value < min_acc:\n",
    "                #min_acc = value\n",
    "        #axes[i].axhline(max_acc - min_acc, linestyle=\"--\", color=colors[j])\n",
    "    if write_image:\n",
    "        fig.savefig(os.path.join('../../plots/pred_with_raw_model', model, f'{model}_dataset_comp.png'), bbox_inches='tight', dpi=200)\n",
    "        fig.savefig(os.path.join('../../plots/pred_with_raw_model', model, f'{model}_dataset_comp.pdf'), bbox_inches='tight', dpi=200)\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_fairness(temp, ff_temp): \n",
    "    model_fairness = {}\n",
    "    model_fairness[\"celebA\"] = {}\n",
    "    model_fairness[\"fairface\"] = {}\n",
    "    for i, cat in enumerate(categories):\n",
    "        zz = []\n",
    "        yy = []\n",
    "        for j, race in enumerate(races):\n",
    "            zz.append(temp[cat][race])\n",
    "            yy.append(ff_temp[cat][race])\n",
    "        model_fairness[\"celebA\"][cat] = (np.array(zz).max(0) - np.array(zz).min(0)).tolist()\n",
    "        model_fairness[\"fairface\"][cat] = (np.array(yy).max(0) - np.array(yy).min(0)).tolist()\n",
    "    return model_fairness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_fairness_comparison(temp, ff_temp, rates, write_image=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch2_2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
