{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision.io import read_image\n",
    "import torchvision.transforms.v2 as transformsv2\n",
    "import sys\n",
    "torch.manual_seed(42)\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "RESNET18_HEIGHT = 224\n",
    "RESNET18_WIDTH = 224\n",
    "\n",
    "class RFW(Dataset):\n",
    "\n",
    "    def __init__(self, img_path, attr_path, transforms, png):\n",
    "\n",
    "        self.attr = pd.read_csv(attr_path).to_numpy()\n",
    "        print(f'attr: {self.attr}')\n",
    "        self.img_path = img_path\n",
    "        self.transforms = transforms\n",
    "        self.png = png\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.attr)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        if self.png:\n",
    "            img =  read_image(os.path.join(self.img_path, self.attr[idx][2], self.attr[idx][1]))\n",
    "        else:\n",
    "            img =  read_image(os.path.join(self.img_path, self.attr[idx][2], self.attr[idx][1].replace(\"png\", \"jpg\")))\n",
    "        return self.transforms(img), torch.from_numpy(self.attr[idx][3:].astype(np.float32)),\\\n",
    "            self.attr[idx][2].split(\"/\")[0], f'{self.attr[idx][2]}/{self.attr[idx][1]}'\n",
    "\n",
    "\n",
    "\n",
    "def create_dataloaders(\n",
    "    img_path, \n",
    "    attr_path, \n",
    "    batch_size, \n",
    "    train_test_ratio=0.7, \n",
    "    png=True, \n",
    "    seed=42\n",
    "):\n",
    "\n",
    "    tfs = transformsv2.Compose([\n",
    "        transformsv2.Resize((RESNET18_HEIGHT, RESNET18_WIDTH)),\n",
    "        transformsv2.ToTensor()\n",
    "    ])\n",
    "\n",
    "    # Create Dataset\n",
    "    data = RFW(img_path, attr_path, tfs, png)\n",
    "\n",
    "    generator = torch.Generator().manual_seed(seed)\n",
    "\n",
    "    trainset_size = int(len(data) * train_test_ratio)\n",
    "    validaset_size = int((len(data) - trainset_size) * 0.5)\n",
    "    testset_size = len(data) - trainset_size - validaset_size\n",
    "\n",
    "    trainset, valset, testset = random_split(data, [trainset_size, validaset_size, testset_size], generator)\n",
    "\n",
    "    # Create data loaders\n",
    "    train_loader = DataLoader(trainset, batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(valset, batch_size)\n",
    "    test_loader = DataLoader(testset, batch_size)\n",
    "\n",
    "    return train_loader, val_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RACE_LABELS = ['Indian', 'Asian', 'African', 'Caucasian']\n",
    "ROOT = '/media/global_data/fair_neural_compression_data/decoded_rfw/decoded_64x64'\n",
    "RFW_LABELS_DIR = \"/media/global_data/fair_neural_compression_data/datasets/RFW/clean_metadata/numerical_labels_sorted.csv\"\n",
    "RATIO = 0.8\n",
    "BATCH_SIZE = 32\n",
    "model_names = ['cheng2020-attn', 'hyperprior', 'mbt2018', 'qarv', 'qres17m']\n",
    "# attribites = ['']\n",
    "# hard coding model_name to be the cheng2020-attn model\n",
    "model_name = 'cheng2020-attn'\n",
    "datasets_names = ['fairface', 'celebA']\n",
    "dataset_name = 'celebA'\n",
    "\n",
    "qualities = ['q_0001', 'q_0009', 'q_1', 'q_2', 'q_3']\n",
    "# mapping model name to corresponding decoded image storage dir.\n",
    "qualities_dict = {'hyperprior':['q_0001', 'q_0009', 'q_1', 'q_2', 'q_3'], \n",
    "                  'mbt2018':['q_0001', 'q_0009', 'q_1', 'q_2', 'q_3'], \n",
    "                  'cheng2020-attn':['q_0001', 'q_0009', 'q_1', 'q_2', 'q_3'], \n",
    "                  'qres17m':['1', '3', '6', '9', '12'], \n",
    "                  'qarv':['lmb_1', 'lmb_4', 'lmb_8', 'lmb_16', 'lmb_32']}\n",
    "model_name_dict = {'hyperprior':'hyperprior', \n",
    "                  'mbt2018':'mbt2018', \n",
    "                  'cheng2020-attn':'cheng2020-attn', \n",
    "                  'qres17m':'qres17m_lmb_64', \n",
    "                  'qarv':'qarv'}\n",
    "\n",
    "for quality in qualities_dict[model_name]:\n",
    "    train_loader, valid_loader, test_loader = create_dataloaders(\n",
    "        f'{ROOT}/{model_name_dict[model_name]}/{dataset_name}/{quality}', \n",
    "        RFW_LABELS_DIR, \n",
    "        BATCH_SIZE, \n",
    "        RATIO\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_file_names = []\n",
    "for batch in test_loader:\n",
    "    test_file_names.extend(list(batch[-1]))\n",
    "# test_file_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "ATTRIBUTE_INDECIES = {\n",
    "    'skin_type': 0,\n",
    "    'lip_type': 1,\n",
    "    'nose_type': 2,\n",
    "    'eye_type': 3,\n",
    "    'hair_type': 4,\n",
    "    'hair_color': 5\n",
    "}\n",
    "\n",
    "def save_race_based_predictions(\n",
    "        models,  \n",
    "        dataloader, \n",
    "        device, \n",
    "        prediction_save_dir,\n",
    "        attributes\n",
    "    ):\n",
    "    all_predictions = {'Indian': {attr: torch.tensor([]) for attr in attributes}, \n",
    "                       'Caucasian': {attr: torch.tensor([]) for attr in attributes}, \n",
    "                       'Asian': {attr: torch.tensor([]) for attr in attributes},  \n",
    "                       'African': {attr: torch.tensor([]) for attr in attributes}}\n",
    "    all_labels = {'Indian': {attr: torch.tensor([]) for attr in attributes}, \n",
    "                  'Caucasian': {attr: torch.tensor([]) for attr in attributes}, \n",
    "                  'Asian': {attr: torch.tensor([]) for attr in attributes}, \n",
    "                  'African': {attr: torch.tensor([]) for attr in attributes}}\n",
    "    all_file_names = {\n",
    "        'Indian': {attr: [] for attr in attributes}, \n",
    "        'Caucasian': {attr: [] for attr in attributes}, \n",
    "        'Asian': {attr: [] for attr in attributes},  \n",
    "        'African': {attr: [] for attr in attributes}\n",
    "    }\n",
    "    print(f'prediction_save_dir: {prediction_save_dir}')\n",
    "    dataloader = tqdm(dataloader, desc=\"Getting Predictions\", unit=\"batch\")\n",
    "    with torch.no_grad():\n",
    "        for j, model in enumerate(models):\n",
    "            model.eval()\n",
    "            for _, data in enumerate(dataloader):\n",
    "                inputs, labels, race, file_names = data\n",
    "                file_names = np.array(list(file_names))\n",
    "                race = np.array(race)\n",
    "\n",
    "                inputs = inputs.to(torch.float).to(device)\n",
    "                labels = labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "\n",
    "                for i, (head, predictions) in enumerate(outputs.items()):\n",
    "                    head_preds = predictions.argmax(dim=1).cpu()\n",
    "\n",
    "                    for race_label in all_labels:\n",
    "                        race_indices = np.array((race == race_label).nonzero()[0])\n",
    "                        race_predictions = head_preds[race_indices]\n",
    "                        race_file_names = file_names[race_indices]\n",
    "                        race_labels = labels[:, ATTRIBUTE_INDECIES[head]][race_indices]\n",
    "                    \n",
    "                        all_predictions[race_label][head] = torch.cat((all_predictions[race_label][head], race_predictions.to('cpu')), dim=0)\n",
    "                        all_labels[race_label][head] = torch.cat((all_labels[race_label][head], race_labels.to('cpu')), dim=0)\n",
    "                        all_file_names[race_label][head].extend(list(race_file_names))\n",
    "    # with open(prediction_save_dir + '/sep_predictions.pkl', 'wb+') as f:\n",
    "    #     pickle.dump(all_predictions, f)\n",
    "    # with open(prediction_save_dir + '/sep_labels.pkl', 'wb+') as f:\n",
    "    #     pickle.dump(all_labels, f)\n",
    "\n",
    "\n",
    "    return all_predictions, all_labels, all_file_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from multi_head_resnet import MultiHeadResNet\n",
    "all_predictions = {}\n",
    "all_labels = {}\n",
    "all_file_names = {}\n",
    "attributes = ['eye_type', 'hair_color', 'hair_type', 'nose_type', 'skin_type']\n",
    "# attributes = ['eye_type']\n",
    "PRED_ROOT = '/media/global_data/fair_neural_compression_data/pred_with_raw_model_debug'# new folder \n",
    "# same <models> list for all the compression models.\n",
    "models = []\n",
    "for attribute in attributes:\n",
    "    # this dir is hardcoded as we store clean model training results here. \n",
    "    attribute_model_path = f'{PRED_ROOT}/hyperprior/celebA/clean/{attribute}_best.pth'\n",
    "    models.append(torch.load(attribute_model_path))\n",
    "\n",
    "\n",
    "# this is True if want to redo the evaluation. If False, we are loading from previous runs to save time. \n",
    "redo_evaluation = False\n",
    "\n",
    "if redo_evaluation:\n",
    "    for model_name in model_names:\n",
    "        print(model_name)\n",
    "        all_predictions[model_name] = {}\n",
    "        all_labels[model_name] = {}\n",
    "        all_file_names[model_name] = {}\n",
    "        for quality in qualities_dict[model_name]:\n",
    "            train_loader, valid_loader, test_loader = create_dataloaders(\n",
    "                f'{ROOT}/{model_name_dict[model_name]}/{dataset_name}/{quality}', \n",
    "                RFW_LABELS_DIR, \n",
    "                BATCH_SIZE, \n",
    "                RATIO\n",
    "            )\n",
    "            print(quality)\n",
    "            all_predictions[model_name][quality], \\\n",
    "            all_labels[model_name][quality], \\\n",
    "            all_file_names[model_name][quality] = \\\n",
    "                save_race_based_predictions(\n",
    "                    models,  \n",
    "                    test_loader, \n",
    "                    'cuda:1', \n",
    "                    \"\",\n",
    "                    attributes\n",
    "                )      \n",
    "else:\n",
    "    # load from saved files\n",
    "    # already have files, so load, instead of re-run the eval. \n",
    "    file = open(\"./raw_model_predictions.pkl\",'rb')\n",
    "    all_predictions = pickle.load(file)\n",
    "    file = open(\"./raw_model_labels.pkl\",'rb')\n",
    "    all_labels = pickle.load(file)\n",
    "    file = open(\"./raw_model_filenames.pkl\",'rb')\n",
    "    all_file_names = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "save evaluation results. Uncomment when need to save evaluation results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save prediction results\n",
    "# with open('./raw_model_predictions.pkl', 'wb+') as f:\n",
    "#     pickle.dump(all_predictions, f)\n",
    "# with open('./raw_model_labels.pkl', 'wb+') as f:\n",
    "#     pickle.dump(all_labels, f)\n",
    "# with open('./raw_model_filenames.pkl', 'wb+') as f:\n",
    "#     pickle.dump(all_file_names, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cheng_preds, cheng_labels = all_predictions['cheng2020-attn'], all_labels['cheng2020-attn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cheng_file_names = all_file_names['cheng2020-attn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrong_preds_file_names = {}\n",
    "\n",
    "for quality in qualities:\n",
    "    wrong_preds_file_names[quality] = {}\n",
    "    for race in RACE_LABELS:\n",
    "        wrong_preds_file_names[quality][race] = {}\n",
    "        for attribute in attributes:\n",
    "            mask = torch.ne(torch.tensor(cheng_preds[quality][race][attribute]), torch.tensor(cheng_labels[quality][race][attribute]))\n",
    "            wrong_preds_file_names[quality][race][attribute] = \\\n",
    "                np.array(cheng_file_names[quality][race][attribute])[np.array(torch.nonzero(mask).squeeze())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "data_path = '/media/global_data/fair_neural_compression_data/decoded_rfw/decoded_64x64'\n",
    "bpp_data = {}\n",
    "datasets = ['celebA', 'fairface']\n",
    "for model_name in ['cheng2020-attn']:\n",
    "    if model_name == 'jpeg':\n",
    "        continue\n",
    "    print(f'model_name: {model_name}')\n",
    "    bpp_data[model_name] = {}\n",
    "    model_path = f'{data_path}/{model_name}'\n",
    "    for dataset in datasets:\n",
    "        print(f'dataset: {dataset}')\n",
    "        bpp_data[model_name][dataset] = {}\n",
    "        dataset_path = f'{model_path}/{dataset}'\n",
    "        for quality in qualities:\n",
    "            stats_path = f'{dataset_path}/{quality}/stats.json'\n",
    "            with open(stats_path, 'r') as json_file:\n",
    "                stats_data = json.load(json_file)\n",
    "            if \"results\" in stats_data:\n",
    "                bpp_data[model_name][dataset][quality] = stats_data['results']['bpp']\n",
    "            elif \"est_bpp\" in stats_data:\n",
    "                bpp_data[model_name][dataset][quality] = stats_data['est_bpp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tian: inspect African classification results\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import random\n",
    "random.seed(42)\n",
    "merged_skin_type={\n",
    "        'African':([4, 5], 3), \n",
    "        'Asian':([3, 2], 1), \n",
    "        'Caucasian':([3, 2], 1), \n",
    "        'Indian':([4,3], 2)\n",
    "}\n",
    "race_of_interest = 'African'\n",
    "attribute_of_interest = 'skin_type'\n",
    "\n",
    "for quality in qualities:\n",
    "    # print(quality)\n",
    "    merged_preds = cheng_preds[quality][race_of_interest][attribute_of_interest].clone()\n",
    "    merged_labels = cheng_labels[quality][race_of_interest][attribute_of_interest].clone()\n",
    "    if attribute_of_interest =='skin_type':\n",
    "        for target in merged_skin_type[race_of_interest][0]:\n",
    "            merged_preds[merged_preds==target] = merged_skin_type[race_of_interest][1]\n",
    "            merged_labels[merged_labels==target] = merged_skin_type[race_of_interest][1]\n",
    "        class_3_indices = set(np.array((merged_labels==3).nonzero().squeeze()))\n",
    "        predict_2_indices = set(np.array((merged_preds==2).nonzero().squeeze()))\n",
    "        intersection_indices = list(class_3_indices.intersection(predict_2_indices))\n",
    "        intersection_filenames = np.array(cheng_file_names[quality][race_of_interest][attribute_of_interest])[intersection_indices]\n",
    "        intersection_filenames = list(intersection_filenames)\n",
    "        # print(len(class_3_indices))\n",
    "        # print(len(predict_2_indices))\n",
    "        # print(len(intersection_indices))\n",
    "\n",
    "selected_intersection_filenames = random.sample(intersection_filenames, 10)\n",
    "print(selected_intersection_filenames)\n",
    "    # print(confusion_matrix(cheng_labels[quality][race_of_interest][attribute_of_interest], cheng_preds[quality][race_of_interest][attribute_of_interest],labels=[0, 1, 2, 3, 4, 5]))\n",
    "    # print(confusion_matrix(merged_labels, merged_preds,labels=[0, 1, 2, 3, 4, 5]))\n",
    "\n",
    "# print(len(cheng_preds[quality][race_of_interest][attribute_of_interest]))\n",
    "\n",
    "# for quality in qualities:\n",
    "#     print(len(wrong_preds_file_names[quality][race_of_interest][attribute_of_interest]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot mis-classified images\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "RFW_ROOT = '/media/global_data/fair_neural_compression_data/datasets/RFW/data_64'\n",
    "fig, axes = plt.subplots(10, 6, figsize=(8, 12))\n",
    "plt.setp(axes, xticks=[], yticks=[], frame_on=False) # remove black borders, no xy axis\n",
    "for i, file_name in enumerate(selected_intersection_filenames):\n",
    "    for j in range(len(qualities) + 1):\n",
    "        if j == len(qualities):\n",
    "            image_path = f'{RFW_ROOT}/{file_name}'\n",
    "        else:\n",
    "            image_path = f'{ROOT}/{\"cheng2020-attn\"}/{dataset_name}/{qualities[j]}/{file_name}'\n",
    "        img = mpimg.imread(image_path)\n",
    "        axes[i][j].imshow(img)\n",
    "plt.savefig(f'../../plots/pred_with_raw_model/{model_name}_African_skin_type_3_to_2_errors.pdf', dpi=300, bbox_inches='tight')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch2_2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
